5/7/21

A long time ago, I read an article about someone who *bred* programs on their
dev machine. They reproduced sexually and eventually eventually evolved ways to
kill each other off.

In nature, organisms need to use energy, maintain homeostasis, and
reproduce. All three criteria can be considered to be met a standard computer
program.

However, they don't generally change, nor do they generally have an instinct to
reproduce themselves as much as possible.

We'll need to create a framework in which for these digital organisms to live.
Let's give them a rudimentary task to perform. They'll need to do it as quickly
as possible and submit the answer. The input will be written into the process's
address space before it is started and it will be expected to write the output
to a particular location when it exits.

A parent process will manage many of these organisms. It will start N of them
for each generation, allowing them to run concurrently. The top M will be bred
together to form the next generation.

We'll start with a simple task and ensure that there are degrees of success to
the task.

Okay, so I'm thinking about the method of communication between the parent and
the child. Shared memory is by far the simples method to use. Unfortunately, a
fork+exec wouldn't work because the exec would wipe out the shared memory.

So what if I didn't use exec? We wouldn't package each organism as an ELF.
Instead, it would just be a "function". The environment would read each genome
in a different thread in the environment process. Each thread would wait on a
wait group for them all to finish, then, all at once, we'd jump to the first
instruction in the genome. Once the task is finished, the organism must signal
the environment that it is finished. A manager thread will notice that the
organism has finished and record the result.

How about this? What if we have a separate concurrent process (or thread?)
monitoring the output of each organism. If it has not made sufficient progress
on its task, then the this god process kills the organism. This God process
would need to be memory protected from the organisms so that they couldn't just
learn how to kill *it*.

Okay, I'm finding it easier to write the initial organism in assembly. It gives
me much more precise control over what appears in the genome.

Okay, now I've got the ability to load in a buffer of executable code and run
it, passing in a single quadword of data.

I think the next step is going to be giving it a buffer to work with. Should we
protect it?  I don't think so. Getting to mess around with other things within
the process will allow us to simulate competition between organisms.

So what will the initial task be? We want something where we can create an
initial suboptimal solution and that can then be gradually evolved to a more
optimal solution. Later on, we'll also want to incorporate some sense of the
energy expended in reaching that conclusion. So how will the environment
determine that? We could use wall clock time, but this requires large stretches
of time. It looks like we can get per-thread CPU usage from the OS. This will
allow us to figure out exactly how much CPU time has been used. This will be
given to us in "clock ticks", which are quite accurate.

The first thought I had was multiplying two numbers together. We can start out
by implementing it as a loop, 8-bit style. Then we hope that, by mutation, we
get a multiplication opcode. Unfortunately, this seems like it would require a
bit of an evolutionary leap. Would we *ever* get there?

Maybe something even simpler. How about calculating 2*(a + b) and we start off
by giving it just a + b? Seems reasonable. So what should the byte layout look
like?

How about something nice and simple. One byte for a, one byte for b, and a third
byte will be the output.

Okay, what about the concurrency model? So far, we've had two ideas. The first
is a more traditional evolutionary algorithm. We run a generation for a fixed
period of time, evaluate its fitness, and then have the environment do the
reproduction. Not the most realistic.

The more realistic option is to encode reproduction into the genome itself. So
the model here becomes.

1. Environment starts a thread, loads a genome, and starts an organism. From
   that point on, the thread belongs to the organism.
2. Periodically, the environment inspects the organism's shared memory. If it
   hasn't been completely enough tasks well enough, it is killed off.
3. The organism never terminates. If it does, this is considered a failure to
   maintain homeostasis. It divides its time between completing the task and
   reproducing.

Okay, so completing computational tasks seems pretty straightforward. But how
does *sexual reproduction* happen? Each organism would have to know how to
introspect itself and produce a gene sequence. Then, we'd have to have males and
females or all hermaphrodites. A male would have to somehow identify a partner and
somehow send that gene sequence to that partner. Then, the female would have to
recombine those two gene sequences into a single gene sequence. Finally, we
would have to instantiate a *new organism* from that gene sequence. How would we
even orchestrate that? They'd have to spawn a new thread and it would have to
somehow be noticed by the managing thread. Very complicated stuff.

Maybe for the moment we just stick to mitosis.

So I've got basic problem scoring set up. Now we'll move onto the concurrency
model.

Okay cool. Now we've got the environment running in a separate thread from the
organism and the environment has the ability to *kill* the organism.

Okay, so under what conditions *should* we kill off an organism? I see two
possible ways. The first option is to keep a running average of the fitness over
a sliding window and kill the organism off only if that running average has
fallen below a threshold. The second option would be to kill it off the very
first time it fails to meet a threshold. I think I'm going to lean toward
leniency here. It should allow more interesting things to evolve.

I also want to incorporate CPU time into the efficiency here. We'll see what
sort of weighting we'll use.

I think I need to go to bed for now. But for reference, I'm currently
experiencing a problem where I'm returning a double that should be 0.9 from
fitness_average, but it's somehow showing up as 0.0 at the call site. I'll take
a deeper look at the disassembly tomorrow.

I stared at the assembly for a long time and saw something that looked like a
complete miscompilation. ... Until I realized that my function that was in
reality returning a double was marked as a uint64_t return type. So there was an
automatic coercion going on. That *needs* to marked as an error, IMO. So I set
up some stricter compilation rules. Will save me time in the future.

I had an idea this morning. We need some way to inject randomness into the
existence of orgnaisms. How, for example, will mutations occur in this system?
In nature, organisms do their best to faithfully reproduce their genome and the
imprecision of their mechanisms along with ambient random events in their
environment (e.g. radiation) cause errors in duplication, recombination, and
transcription.

How will we handle that in this environment? We can have the environment thread
randomly select and change bytes in both the organism's buffer *and* its code
space. I think algorithsm can be developed to deal with random changes in the
working space, but random changes in the instruction space are likely to just
cause a segfault or some other signal (like SIGFPE), which would *kill* the
organism. Things are much more lenient in nature, though. An arbitrary change in
a gene is likely to cause a slight change in the proteins expressed, but it is
*not* likely to completely break the process of transcription. Perhaps we should
also be more lenient. We could restart the organism from the beginning. Or maybe
we could simply skip over the offending instruction and move onto the next one.
This recasts signal-generating instructions as _stop codons_. The question then
is what we should use as a start codon? For the moment, let's go with resuming
at the next instruction following that and revisit it later if it becomes a
problem.

Now, however, we need to differentiate between an intentioned kill signal
generated by the environment and an unintential signal generated by the code
itself. Let's just use SIGTERM to kill the thread off.

Hm. It actually might not be easy to jump to the next instruction. We _do_ get
access to the instruction pointer from when the signal was generated, but
there's no simple way to use that information to figure out the address of the
next instruction. Maybe if we were on a RISC system instead... So either we can
try to progress by 1 or 2 bytes at a time, *or* we can revisit the start codon
approach. But what would we use as a "start codon"? A noop? Anything that's
*not* a no-op? It's a hard problem...

So what if we try to just muddle through one byte at a time? Until we get to the
next instruction, odds are that we'll just be generating more signals. Things
get *really* weird though when we reach something that *isn't* an intentional
instruction when read from the beginning, but *is* when put the instruction
pointer at something that isn't "intended" to be an instruction. If you have a
sequence of instructions like this that are valid when read from two different
offsets, you could actually have a conditional with both branches encoded by the
same code. Weird. Would be very hard to debug if that evolved. Let's give it a
shot.

I'll test this out by adding a SIGSEGV-generating instruction to the progenitor
organism and making sure that it functions nonetheless.

Okay, so something weird is happening. After the initial segfault, *every*
instruction is causing a segfault.

Okay, turns out that whole "skew" thing I was worried about was very much
warranted. Let's look at our progenitor organism:

   0:	66 0f b6 18          	movzbw (%rax),%bx
   4:	66 0f b6 48 01       	movzbw 0x1(%rax),%cx
   9:	ba 00 00 00 00       	mov    $0x0,%edx
   e:	66 8b 12             	mov    (%rdx),%dx
  11:	66 01 cb             	add    %cx,%bx
  14:	66 89 58 02          	mov    %bx,0x2(%rax)
  18:	eb e6                	jmp    0x0
  1a:	c3                   	ret  

So we get to the instruction at 0xe and segfault. We move forward a byte and try
0xf, That segfaults too. _But 0x10 doesn't_. So what does it get decoded as? An
online disassembler tells me that if we interpret the next 3 bytes as an
instruction, we get

0:  12 66 01                adc    ah,BYTE PTR [rsi+0x1]

So we add the value located at RSI+1 (which is some random value) into AH. Okay,
now rax is screwed up. We could be up to 256 bytes away from the beginning of
the buffer. The next instruction after this is 0x13, which logs indicate is
segfaulting. So do 0x14 and 0x15. But 0x16 doesn't, which -- again -- isn't a
"real" instruction. So what do we interpret it as?

0:  58                      pop    rax
1:  02 eb                   add    ch,bl

So next we completely overwrite rax with some junk on the stack. Guess that
means the previous spurious instruction didn't matter anyway. But I guess we all
just screwed up the stack. Good thing we weren't using that anyway. (maybe this
is the reason we're getting a segfault at the end? :think:) Then we do something
random that screws up the state that was in rcx and rbx.

Next, 0x19 fails. The disassembler tells me it was trying to do this:

0:  e6 c3                   out    0xc3,al

But I guess there *isn't* an 0xc3 port.

Finally, we execute the `ret` instruction. But that involves returning to an
address added to the stack by the call instruction. Then bad stuff happens. I
can only assume we resume at a pthread_function.

Well, I've had my first instance of an organism managing to get out of the
mortal realm and stab God. It looks like the organism. This was always a danger
of the threaded approach I've been using. I really might have to figure out some
way to use a multithreaded approach instead. I assume this sort of thing is
going to happen a *lot*. It needs to kill the organism, not _end nature_. I
probalby wont' do that today though. that's going to be a decent overhaul.

My thought was that 0x0000 could be a start codon, but it seems that that
disassembles to

0:  00 00                   add    BYTE PTR [rax],al

Not a noop. Maybe I need to have many codons and actively seek them out? But,
like, what about long segfaulting instructions that _include_ 0x90?  Those could
result in the same problem. But y'know what? Those are few enough that we can
just let evolution weed them out.

Boom! We've made things more lenient! All the organism has to do is pad its
genome with nops.

So I'm thinking about this isolation problem. We *do* want different organisms
to interact with one another, so it's totally appropriate for them to share an
address space. But the environment needs to be isolated. I'm thinking the
environment should run in one process, while organisms run in another process.
Each organism will be a single thread within that process. The environment
process will use ptrace to interact with each organism and enforce constraints.
